{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Packages -----------------------------------------------#\n",
    "\n",
    "# Data Analysis\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import metpy.calc as mpcalc\n",
    "import matplotlib.dates as dates\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.interpolate import griddata\n",
    "\n",
    "# Timing Processes and Progress\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "# make sure the figures plot inline rather than at the end\n",
    "%matplotlib inline\n",
    "\n",
    "outfn = 'chl_25km_processed.nc'\n",
    "\n",
    "\n",
    "# get data\n",
    "path = '/home/jennap/projects/LRGROUP/shared_data/chl-globcolor-case-1-and-case-2-waters/concatenated-daily/'\n",
    "# chlinfn = 'all_L3m_AV_CHL1_100km_global_monthly_merged_1997_2020.nc'\n",
    "chlinfn = 'all_L3m_AV_CHL1_25km_global_monthly_merged_1997_2020.nc'\n",
    "\n",
    "ds = xr.open_dataset(path + chlinfn)\n",
    "ds\n",
    "# ds.chl1_mean.attrs[\"units\"]\n",
    "# # print(ds.keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subset ------------------------------------------------#\n",
    "# Create slice variables to subset domain before finding means\n",
    "lat_slice = slice(-20, 30) # bounds inclusive\n",
    "lon_slice = slice(35, 120) # bounds inclusive\n",
    "time_slice = slice('1997-09-04','2019-12-31')\n",
    "\n",
    "# Get data, selecting lat/lon slice\n",
    "daily_chl = ds['chl1_mean'].sel(lat=lat_slice,lon=lon_slice, time = time_slice)\n",
    "lat = daily_chl.lat.values\n",
    "lon = daily_chl.lon.values\n",
    "daily_chl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1997-2012 anomaly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_slice = slice('1997-09-04','2012-12-31')\n",
    "mchl = daily_chl.sel(lat=lat_slice,lon=lon_slice, time = time_slice).mean(axis=0,skipna=True)\n",
    "daily_chla = daily_chl - np. nanmean(daily_chl,0)\n",
    "daily_chla"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detrend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# stack lat and lon into a single dimension called allpoints\n",
    "stacked = daily_chla.stack(allpoints=['lat','lon'])\n",
    "# set places where there are nans to zero since polyfit can't deal with them\n",
    "stacked_nonan = stacked.fillna(0)\n",
    "\n",
    "# convert date to a number to polyfit can handle it\n",
    "datenum = dates.date2num(stacked_nonan.time)\n",
    "daily_chla_slope, daily_chla_intercept = np.polyfit(datenum, stacked_nonan, 1)\n",
    "\n",
    "#reshape the data\n",
    "daily_chla_slope = np.reshape(daily_chla_slope, daily_chla.shape[1:3])\n",
    "daily_chla_intercept = np.reshape(daily_chla_intercept, daily_chla.shape[1:3])\n",
    "\n",
    "# define a function to compute a linear trend of a timeseries\n",
    "def linear_detrend(y):\n",
    "    x = dates.date2num(y.time)\n",
    "    m, b = np.polyfit(x, y, 1)\n",
    "    # we need to return a dataarray or else xarray's groupby won't be happy\n",
    "    return xr.DataArray(y - (m*x + b))\n",
    "\n",
    "# apply the function over allpoints to calculate the trend at each point\n",
    "daily_chla_dtrnd = stacked_nonan.groupby('allpoints').apply(linear_detrend)\n",
    "# unstack back to lat lon coordinates\n",
    "daily_chla_dtrnd = daily_chla_dtrnd.unstack('allpoints')\n",
    "\n",
    "# fill all points we set originally to zero back to nan\n",
    "daily_chla_dtrnd = daily_chla_dtrnd.where(~np.isnan(daily_chla))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find global means for comparison\n",
    "stacked = daily_chla.stack(allpoints=['lat','lon'])\n",
    "global_mean = stacked.mean(dim='allpoints',skipna=True)\n",
    "global_mean.plot()\n",
    "\n",
    "# find global means for comparison\n",
    "stacked = daily_chla_dtrnd.stack(allpoints=['lat','lon'])\n",
    "global_mean_dtrnd = stacked.mean(dim='allpoints',skipna=True)\n",
    "global_mean_dtrnd.plot()\n",
    "plt.legend"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Downsample to Monthly and Seasonal Temporal Resolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# monthly\n",
    "mon_chla_dtrnd = daily_chla_dtrnd.resample(time='1MS').mean(dim=\"time\")\n",
    "# seasonal\n",
    "seas_chla_dtrnd = daily_chla_dtrnd.resample(time='QS-DEC').mean(dim=\"time\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find Climatologies \n",
    "Resources: [link](http://xarray.pydata.org/en/stable/examples/monthly-means.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# -------------------------------------------\n",
    "# weighted seasonal\n",
    "# -------------------------------------------\n",
    "\n",
    "# get months\n",
    "month_length = mon_chla_dtrnd.time.dt.days_in_month\n",
    "\n",
    "# calculate the weights by grouping by 'time.season'.\n",
    "weights = month_length.groupby('time.season') / month_length.groupby('time.season').sum()\n",
    "\n",
    "# calculate the weighted average\n",
    "chla_seas_clim = (daily_chla_dtrnd * weights).groupby('time.season').sum(dim='time')   \n",
    "\n",
    "# set the places that are now zero from the weights to nans\n",
    "chla_seas_clim = chla_seas_clim.where(chla_seas_clim != 0,np.nan) # for some reason .where sets the locations not in the condition to nan by default\n",
    "\n",
    "# -------------------------------------------\n",
    "# monthly\n",
    "# -------------------------------------------\n",
    "\n",
    "chla_mon_clim = daily_chla_dtrnd.groupby('time.month').mean('time') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find Anomalies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# monthly avg data - monthly climatology\n",
    "mon_chla_mon_anom = daily_chla_dtrnd.groupby('time.month') - chla_mon_clim\n",
    "\n",
    "# seasonal avg data - seasonal climatology\n",
    "seas_chla_seas_anom = daily_chla_dtrnd.groupby('time.season') - chla_seas_clim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to xarray dataset\n",
    "ds=xr.Dataset(coords={'lon': mon_chla_dtrnd.lon,\n",
    "                    'lat': mon_chla_dtrnd.lat,\n",
    "                    'time': mon_chla_dtrnd.time})\n",
    "\n",
    "# add variables to dataset\n",
    "\n",
    "ds[\"mon_chla\"]=xr.DataArray(mon_chla_dtrnd,dims = ['time','lat', 'lon'],\n",
    "                     coords =[mon_chla_dtrnd.time,mon_chla_dtrnd.lat,mon_chla_dtrnd.lon])\n",
    "ds[\"seas_chla\"]=xr.DataArray(seas_chla_dtrnd,dims = ['season_time','lat', 'lon'],\n",
    "                     coords =[seas_chla_dtrnd.time,mon_chla_dtrnd.lat,mon_chla_dtrnd.lon])\n",
    "\n",
    "# clim\n",
    "ds[\"chla_mon_clim\"]=xr.DataArray(chla_mon_clim,dims = ['month','lat', 'lon'],\n",
    "                     coords =[chla_mon_clim.month,mon_chla_dtrnd.lat,mon_chla_dtrnd.lon])\n",
    "ds[\"chla_seas_clim\"]=xr.DataArray(chla_seas_clim,dims = ['season','lat', 'lon'],\n",
    "                     coords =[chla_seas_clim.season,mon_chla_dtrnd.lat,mon_chla_dtrnd.lon])\n",
    "\n",
    "\n",
    "# anom\n",
    "ds[\"mon_chla_mon_anom\"]=xr.DataArray(mon_chla_mon_anom,dims = ['time','lat', 'lon'],\n",
    "                     coords =[mon_chla_mon_anom.time,mon_chla_dtrnd.lat,mon_chla_dtrnd.lon])\n",
    "ds[\"seas_chla_seas_anom\"]=xr.DataArray(seas_chla_seas_anom,dims = ['season_time','lat', 'lon'],\n",
    "                     coords =[seas_chla_seas_anom.time,mon_chla_dtrnd.lat,mon_chla_dtrnd.lon])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# delete if already present\n",
    "if os.path.isfile(outfn):\n",
    "    os.remove(outfn)\n",
    "\n",
    "ds.to_netcdf(outfn,mode='w',format = \"NETCDF4\")\n",
    "\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.pcolormesh(ds.chla_seas_clim[0,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
