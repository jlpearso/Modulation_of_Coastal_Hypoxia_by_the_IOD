{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='darkblue'>Setup</font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Packages -----------------------------------------------#\n",
    "\n",
    "# Data Analysis\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "from scipy.ndimage import gaussian_filter\n",
    "\n",
    "# Plotting\n",
    "import cartopy.crs as ccrs\n",
    "from cartopy.feature import LAND\n",
    "import cartopy.feature as cfeature\n",
    "import matplotlib.gridspec as gridspec\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pyplot as mpl\n",
    "\n",
    "# Timing Processes\n",
    "import time\n",
    "\n",
    "# make sure the figures plot inline rather than at the end\n",
    "%matplotlib inline\n",
    "\n",
    "# Get Data ----------------------------------------------#\n",
    "\n",
    "# get data from tigress - currently this is Liao's\n",
    "path = '/home/jennap/projects/LRGROUP/shared_data/Merged_ARGO_WOD_GOSHIP/'\n",
    "infn = 'Profiles_temp_psal_doxy.nc'\n",
    "\n",
    "ds = xr.open_dataset(path + infn)\n",
    "# print(ds.keys())\n",
    "\n",
    "# change time variable ----------------------------------#\n",
    "# set the units to be something xarray can decode\n",
    "ds.time.attrs['units'] = 'days since 01-01-1800'\n",
    "#re-decode the dataset\n",
    "ds = xr.decode_cf(ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='darkblue'>Quality Control</font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.DataArray 'temp' ()>\n",
      "array(17944)\n",
      "17944\n"
     ]
    }
   ],
   "source": [
    "# # remove shelf\n",
    "# shelf_pres_cutoff = 200\n",
    "\n",
    "# # take only data that is below this pressure level\n",
    "# below_shelf_temp = ds.temp[:,ds.pres >= shelf_pres_cutoff];\n",
    "# below_shelf_doxy = ds.doxy[:,ds.pres >= shelf_pres_cutoff];\n",
    "\n",
    "# # find if all the data are nans below this\n",
    "# below_shelf_temp_ind = (np.sum(~np.isnan(below_shelf_temp),1) <1)\n",
    "# below_shelf_doxy_ind = (np.sum(~np.isnan(below_shelf_doxy),1) <1)\n",
    "\n",
    "# # set the whole columns to those on the shelf to NaNs\n",
    "# ds.temp[below_shelf_temp_ind,:] = np.nan;\n",
    "# ds.doxy[below_shelf_doxy_ind,:] = np.nan;\n",
    "\n",
    "# # find data above 500dbars\n",
    "# upper_temp = ds.temp[:,ds.pres<500]\n",
    "# upper_doxy = ds.doxy[:,ds.pres<500]\n",
    "\n",
    "# # set profiles with less than 10 points in upper ocean to nans\n",
    "# temp_qc = ds.temp\n",
    "# temp_ind = (np.sum(~np.isnan(upper_temp),1) <10)\n",
    "# temp_qc[temp_ind,:] = np.nan\n",
    "\n",
    "# doxy_qc = ds.doxy\n",
    "# doxy_ind = (np.sum(~np.isnan(upper_doxy),1) <10)\n",
    "# doxy_qc[doxy_ind,:] = np.nan\n",
    "\n",
    "# #add to dataset\n",
    "# ds['temp_qc'] = temp_qc\n",
    "# ds['doxy_qc'] = doxy_qc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Find one-sided dT/dp and dO/dp\n",
    "# temp_grad = temp_qc.diff(\"pres\")/ds.pres.diff(\"pres\")\n",
    "# doxy_grad = doxy_qc.diff(\"pres\")/ds.pres.diff(\"pres\")\n",
    "\n",
    "# # average pressures\n",
    "# pres_grad = (np.array(ds.pres[1:]) + np.array(ds.pres[:-1]))/2\n",
    "\n",
    "# #add to dataset\n",
    "# ds['temp_grad'] = xr.DataArray(temp_grad,dims = ['prof','pres_grad'],coords =[ds.prof,pres_grad])\n",
    "# ds['doxy_grad'] = xr.DataArray(doxy_grad,dims = ['prof','pres_grad'],coords =[ds.prof,pres_grad])\n",
    "\n",
    "# # lightly smooth profiles\n",
    "# temp_grad_sm_10 = ds.temp_grad.rolling(pres_grad=13, center=True).mean()\n",
    "# doxy_grad_sm_10 = ds.doxy_grad.rolling(pres_grad=7, center=True).mean()\n",
    "\n",
    "# #add to dataset\n",
    "# ds['temp_grad_sm_10'] = xr.DataArray(temp_grad_sm_10,dims = ['prof','pres_grad'],coords =[ds.prof,pres_grad])\n",
    "# ds['doxy_grad_sm_10'] = xr.DataArray(doxy_grad_sm_10,dims = ['prof','pres_grad'],coords =[ds.prof,pres_grad])\n",
    "\n",
    "# Find centered dT/dp and dO/dp\n",
    "temp_grad = ds.temp.differentiate(\"pres\")/ds.pres.differentiate(\"pres\")\n",
    "doxy_grad = ds.doxy.differentiate(\"pres\")/ds.pres.differentiate(\"pres\")\n",
    "\n",
    "pres_grad = ds.pres\n",
    "\n",
    "#add to dataset\n",
    "ds['temp_grad'] = xr.DataArray(temp_grad,dims = ['prof','pres_grad'],coords =[ds.prof,pres_grad])\n",
    "ds['doxy_grad'] = xr.DataArray(doxy_grad,dims = ['prof','pres_grad'],coords =[ds.prof,pres_grad])\n",
    "\n",
    "# lightly smooth profiles\n",
    "temp_grad_sm_10[pr,:] = upper_temp.rolling(pres_grad=13, center=True).mean()\n",
    "doxy_grad_sm_10[pr,:] = upper_doxy.rolling(pres_grad=7, center=True).mean()\n",
    "\n",
    "#add to dataset\n",
    "ds['temp_grad_sm_10'] = xr.DataArray(temp_grad_sm_10,dims = ['prof','pres_grad'],coords =[ds.prof,pres_grad])\n",
    "ds['doxy_grad_sm_10'] = xr.DataArray(doxy_grad_sm_10,dims = ['prof','pres_grad'],coords =[ds.prof,pres_grad])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #mask the nans in the arrays so that the functions work as expected \n",
    "# temp_grad = np.ma.masked_array(ds.temp_grad, np.isnan(ds.temp_grad))\n",
    "# doxy_grad = np.ma.masked_array(ds.doxy_grad, np.isnan(ds.doxy_grad))\n",
    "\n",
    "# temp_grad_sm_10 = np.ma.masked_array(ds.temp_grad_sm_10, np.isnan(ds.temp_grad_sm_10))\n",
    "# doxy_grad_sm_10 = np.ma.masked_array(ds.doxy_grad_sm_10, np.isnan(ds.doxy_grad_sm_10))\n",
    "\n",
    "# # find maximum negative gradients (min grad)\n",
    "# temp_grad_min_ind = np.nanargmin(temp_grad,1)\n",
    "# doxy_grad_min_ind = np.nanargmin(doxy_grad,1)\n",
    "\n",
    "# temp_grad_sm_10_min_ind = np.nanargmin(temp_grad_sm_10,1)\n",
    "# doxy_grad_sm_10_min_ind = np.nanargmin(doxy_grad_sm_10,1)\n",
    "\n",
    "# # take the pressure value at the min index\n",
    "# TCD = pres_grad[temp_grad_min_ind]\n",
    "# OCD = pres_grad[doxy_grad_min_ind]\n",
    "\n",
    "# TCD_sm_10 = pres_grad[temp_grad_sm_10_min_ind]\n",
    "# OCD_sm_10 = pres_grad[doxy_grad_sm_10_min_ind]\n",
    "\n",
    "# #set places where profiles were all nans to nan\n",
    "# TCD[np.sum(~np.isnan(temp_qc),1) <1] = np.nan\n",
    "# OCD[np.sum(~np.isnan(doxy_qc),1) <1] = np.nan\n",
    "\n",
    "# TCD_sm_10[np.sum(~np.isnan(temp_qc),1) <1] = np.nan\n",
    "# OCD_sm_10[np.sum(~np.isnan(doxy_qc),1) <1] = np.nan\n",
    "\n",
    "# # set all values that are lower than 500dbar to nan\n",
    "# TCD[TCD > 500] = np.nan\n",
    "# OCD[OCD > 500] = np.nan\n",
    "\n",
    "# TCD_sm_10[TCD_sm_10 > 500] = np.nan\n",
    "# OCD_sm_10[OCD_sm_10 > 500] = np.nan\n",
    "\n",
    "# #add to dataset\n",
    "# ds['TCD'] = xr.DataArray(TCD,dims = ['prof'],coords =[ds.prof])\n",
    "# ds['OCD'] = xr.DataArray(OCD,dims = ['prof'],coords =[ds.prof])\n",
    "\n",
    "# ds['TCD_sm_10'] = xr.DataArray(TCD_sm_10,dims = ['prof'],coords =[ds.prof])\n",
    "# ds['OCD_sm_10'] = xr.DataArray(OCD_sm_10,dims = ['prof'],coords =[ds.prof])\n",
    "\n",
    "\n",
    "#mask the nans in the arrays so that the functions work as expected \n",
    "temp_grad = np.ma.masked_array(ds.temp_grad, np.isnan(ds.temp_grad))\n",
    "doxy_grad = np.ma.masked_array(ds.doxy_grad, np.isnan(ds.doxy_grad))\n",
    "\n",
    "temp_grad_sm_10 = np.ma.masked_array(ds.temp_grad_sm_10, np.isnan(ds.temp_grad_sm_10))\n",
    "doxy_grad_sm_10 = np.ma.masked_array(ds.doxy_grad_sm_10, np.isnan(ds.doxy_grad_sm_10))\n",
    "\n",
    "# find data above 500dbars\n",
    "upper_temp_grad = temp_grad[:,ds.pres<500]\n",
    "upper_doxy_grad = doxy_grad[:,ds.pres<500]\n",
    "\n",
    "upper_temp_grad_sm_10 = temp_grad_sm_10[:,ds.pres<500]\n",
    "upper_doxy_grad_sm_10 = doxy_grad_sm_10[:,ds.pres<500]\n",
    "\n",
    "# find maximum negative gradients (min grad)\n",
    "upper_temp_grad_min_ind = np.nanargmin(upper_temp_grad,1)\n",
    "upper_doxy_grad_min_ind = np.nanargmin(upper_doxy_grad,1)\n",
    "\n",
    "upper_temp_grad_sm_10_min_ind = np.nanargmin(upper_temp_grad_sm_10,1)\n",
    "upper_doxy_grad_sm_10_min_ind = np.nanargmin(upper_doxy_grad_sm_10,1)\n",
    "\n",
    "# take the pressure value at the min index provided there are at \n",
    "# least 10 points above 500 dbars\n",
    "\n",
    "temp_mind_pt_ind = np.sum(np.finite(upper_temp),1) >10\n",
    "doxy_mind_pt_ind = np.sum(np.finite(doxy_temp),1) >10\n",
    "\n",
    "temp_mind_pt_ind_sm_10 = np.sum(np.finite(upper_temp_sm_10),1) >10\n",
    "doxy_mind_pt_ind_sm_10 = np.sum(np.finite(doxy_temp_sm_10),1) >10\n",
    "\n",
    "TCD = pres_grad[upper_temp_grad_min_ind & temp_mind_pt_ind]\n",
    "OCD = pres_grad[upper_doxy_grad_min_ind & doxy_mind_pt_ind]\n",
    "\n",
    "TCD_sm_10 = pres_grad[upper_temp_grad_sm_10_min_ind & temp_mind_pt_ind_sm_10]\n",
    "OCD_sm_10 = pres_grad[upper_doxy_grad_sm_10_min_ind & doxy_mind_pt_ind_sm_10]\n",
    "\n",
    "#set places where profiles were all nans to nan\n",
    "TCD[np.sum(~np.isnan(ds.temp),1) <1] = np.nan\n",
    "OCD[np.sum(~np.isnan(ds.doxy),1) <1] = np.nan\n",
    "\n",
    "TCD_sm_10[np.sum(~np.isnan(ds.temp),1) <1] = np.nan\n",
    "OCD_sm_10[np.sum(~np.isnan(ds.doxy),1) <1] = np.nan\n",
    "\n",
    "# set all values that are lower than 500dbar to nan\n",
    "TCD[TCD > 500] = np.nan\n",
    "OCD[OCD > 500] = np.nan\n",
    "\n",
    "TCD_sm_10[TCD_sm_10 > 500] = np.nan\n",
    "OCD_sm_10[OCD_sm_10 > 500] = np.nan\n",
    "\n",
    "#add to dataset\n",
    "ds['TCD'] = xr.DataArray(TCD,dims = ['prof'],coords =[ds.prof])\n",
    "ds['OCD'] = xr.DataArray(OCD,dims = ['prof'],coords =[ds.prof])\n",
    "\n",
    "ds['TCD_sm_10'] = xr.DataArray(TCD_sm_10,dims = ['prof'],coords =[ds.prof])\n",
    "ds['OCD_sm_10'] = xr.DataArray(OCD_sm_10,dims = ['prof'],coords =[ds.prof])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare Profiles and TCD/OCD for different regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (16,10))\n",
    "\n",
    "ax = plt.subplot(1,2,1)\n",
    "\n",
    "#subset data\n",
    "thresh = 400\n",
    "boxlat = ds.lat[TCD > thresh]\n",
    "boxlon = ds.lon[TCD > thresh]\n",
    "boxtemp = ds.temp[TCD > thresh,:]\n",
    "boxTCD = ds.TCD[TCD > thresh]\n",
    "\n",
    "for pr in range(boxtemp.shape[0]):\n",
    "    p = ax.plot(boxtemp[pr,:],ds.pres,'.')\n",
    "    plt.hlines(boxTCD[pr],0,18)\n",
    "ax.set_ylim(ax.get_ylim()[::-1])\n",
    "ax.set_title('Unsmoothed Temperature and TCD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define bounding box\n",
    "# eAS = [5,30,40,65]\n",
    "# wAS = [5,30,65,80]\n",
    "# eBoB = [5,30,80,90]\n",
    "# wBoB = [5,30,90,100]\n",
    "\n",
    "# # plot titles\n",
    "# titles = ['West AS','East AS','West BoB','East BoB']\n",
    "# locs = [wAS,eAS,wBoB,eBoB]\n",
    "\n",
    "# fig = plt.figure(figsize = (16,20))\n",
    "\n",
    "# for ll,loc in enumerate(locs):\n",
    "    \n",
    "#     ax = plt.subplot(3,2,ll+1)\n",
    "#     #subset data\n",
    "#     ind = (ds.lat > loc[0]) & (ds.lat < loc[1]) & (ds.lon > loc[2]) & (ds.lon < loc[3])\n",
    "#     boxlat = ds.lat[ind]\n",
    "#     boxlon = ds.lon[ind]\n",
    "#     boxtemp = ds.temp[ind,:]\n",
    "#     for pr in range(boxtemp.shape[0]):\n",
    "#         p = ax.plot(boxtemp[pr,:],ds.pres)\n",
    "#         plt.hlines(ds.TCD[pr],0,18)\n",
    "#     ax.set_ylim(ax.get_ylim()[::-1])\n",
    "#     ax.set_title('Unsmoothed Temperature and TCD ' + titles[ll])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define bounding box\n",
    "# eAS = [5,30,40,65]\n",
    "# wAS = [5,30,65,80]\n",
    "# eBoB = [5,30,80,90]\n",
    "# wBoB = [5,30,90,100]\n",
    "\n",
    "# # plot titles\n",
    "# titles = ['West AS','East AS','West BoB','East BoB']\n",
    "# locs = [wAS,eAS,wBoB,eBoB]\n",
    "\n",
    "# fig = plt.figure(figsize = (16,20))\n",
    "\n",
    "# for ll,loc in enumerate(locs):\n",
    "    \n",
    "#     ax = plt.subplot(3,2,ll+1)\n",
    "#     #subset data\n",
    "#     ind = (ds.lat > loc[0]) & (ds.lat < loc[1]) & (ds.lon > loc[2]) & (ds.lon < loc[3])\n",
    "#     boxlat = ds.lat[ind]\n",
    "#     boxlon = ds.lon[ind]\n",
    "#     boxdoxy = ds.doxy[ind,:]\n",
    "#     for pr in range(boxdoxy.shape[0]):\n",
    "#         p = ax.plot(boxdoxy[pr,:],ds.pres)\n",
    "# #         plt.hlines(ds.OCD[pr],0,18)\n",
    "#     ax.set_ylim(ax.get_ylim()[::-1])\n",
    "#     ax.set_title('Unsmoothed Oxygen and OCD ' + titles[ll])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scatterplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting\n",
    "def add_land(ax,bounds):\n",
    "    from cartopy.mpl.gridliner import LONGITUDE_FORMATTER, LATITUDE_FORMATTER\n",
    "    ax.add_feature(cfeature.LAND,color='gray',zorder = 1)\n",
    "    ax.background_patch.set_facecolor('k')\n",
    "    ax.coastlines(resolution='110m',zorder = 2)\n",
    "    g = ax.gridlines(draw_labels=True,alpha=0)\n",
    "    g.xlabels_top = False\n",
    "    g.ylabels_right = False\n",
    "    g.xlabel_style = {'size': 15}\n",
    "    g.ylabel_style = {'size': 15}\n",
    "    g.xformatter = LONGITUDE_FORMATTER\n",
    "    g.yformatter = LATITUDE_FORMATTER\n",
    "    ax.axes.axis('tight')\n",
    "    ax.set_extent(bounds, crs=ccrs.PlateCarree())\n",
    "\n",
    "# limits \n",
    "cmin = 20\n",
    "cmax = 160\n",
    "bounds = [35,120,-20,30]\n",
    "sz = .5\n",
    "cmap = plt.cm.Spectral # plt.cm.PuOr\n",
    "\n",
    "fig, axes = plt.subplots(nrows = 2, ncols = 2,figsize=(16,10),subplot_kw={'projection': ccrs.PlateCarree()})\n",
    "\n",
    "p = axes[0,0].scatter(ds.lon,ds.lat,s=sz,marker = '.',c=ds.TCD,cmap=cmap,vmin=cmin,vmax=cmax,\n",
    "                       transform=ccrs.PlateCarree())\n",
    "add_land(axes[0,0],bounds)\n",
    "axes[0,0].set_title('Unsmoothed and Unfiltered')\n",
    "axes[0,0].set_xlabel('Longitude')\n",
    "axes[0,0].set_ylabel('Latitude')\n",
    "\n",
    "\n",
    "p2 = axes[0,1].scatter(ds.lon,ds.lat,s=sz,marker = '.',c=ds.TCD_sm_10,cmap=cmap, vmin=cmin,vmax=cmax,\n",
    "                       transform=ccrs.PlateCarree())\n",
    "add_land(axes[0,1],bounds)\n",
    "axes[0,1].set_title('50 dbar Vertically Smoothed')\n",
    "axes[0,1].set_xlabel('Longitude')\n",
    "\n",
    "p4 = axes[1,0].scatter(ds.lon,ds.lat,s=sz,marker = '.',c=ds.OCD,cmap=cmap,vmin=cmin,vmax=cmax,\n",
    "                       transform=ccrs.PlateCarree())\n",
    "add_land(axes[1,0],bounds)\n",
    "axes[1,0].set_title('Unsmoothed and Unfiltered')\n",
    "axes[1,0].set_xlabel('Longitude')\n",
    "axes[1,0].set_ylabel('Latitude')\n",
    "\n",
    "\n",
    "p5 = axes[1,1].scatter(ds.lon,ds.lat,s=sz,marker = '.',c=ds.OCD_sm_10,cmap=cmap, vmin=cmin,vmax=cmax,\n",
    "                       transform=ccrs.PlateCarree())\n",
    "add_land(axes[1,1],bounds)\n",
    "axes[1,1].set_title('50 dbar Vertically Smoothed')\n",
    "axes[1,1].set_xlabel('Longitude')\n",
    "\n",
    "\n",
    "cbar_ax = fig.add_axes([0.925, 0.125, 0.02, 0.75])\n",
    "cbar = fig.colorbar(p,cax=cbar_ax, pad=0.04)\n",
    "cbar.set_label('Thermocline and Oxycline Depth ($dbar$)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binned Maps\n",
    "\n",
    "https://stackoverflow.com/questions/40465026/groupby-bins-on-two-variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def latlonbin(invar,lat,lon,date,binwidth):\n",
    "    import numpy as np\n",
    "    \n",
    "    # create a pandas dataframe\n",
    "    df = pd.DataFrame(dict(\n",
    "            invar = np.array(invar),\n",
    "            lat= np.array(lat),\n",
    "            lon= np.array(lon),\n",
    "            date = np.array(date)\n",
    "        ))\n",
    "    \n",
    "    # # add in a column for the month\n",
    "    df['month'] = pd.DatetimeIndex(df['date']).month\n",
    "\n",
    "    # create 1 degree bins\n",
    "    latedges = np.arange(lat.min()-(binwidth/2),lat.max()+(binwidth/2),binwidth)\n",
    "    lat_inds = list(range(len(latedges)-1))\n",
    "\n",
    "    lonedges = np.arange(lon.min()-(binwidth/2),lon.max()+(binwidth/2),binwidth)\n",
    "    lon_inds = list(range(len(lonedges)-1))\n",
    "\n",
    "    latbins = latedges[1:]-(binwidth/2)\n",
    "    lonbins = lonedges[1:]-(binwidth/2)\n",
    "\n",
    "    df['latedges'] = pd.cut(lat, latedges)\n",
    "    df['lonedges'] = pd.cut(lon, lonedges)\n",
    "    df['latbins_ind'] = pd.cut(lat, latedges,labels = lat_inds)\n",
    "    df['lonbins_ind'] = pd.cut(lon, lonedges,labels = lon_inds)\n",
    "    df['lat_lon_indx']=df.groupby(['latbins_ind', 'lonbins_ind']).ngroup()\n",
    "    grouped = df.groupby(['latbins_ind', 'lonbins_ind'])\n",
    "\n",
    "    invar_BINNED = np.zeros((len(latbins),len(lonbins)), dtype=np.ndarray)\n",
    "    invar_BINNED[:] = np.nan\n",
    "\n",
    "    invar_binned_ave = np.zeros((len(latbins),len(lonbins)), dtype=np.ndarray)\n",
    "    invar_binned_ave[:] = np.nan\n",
    "\n",
    "\n",
    "    #extract the data for each group\n",
    "    for name, group in grouped:\n",
    "        i = np.array(group.latbins_ind)\n",
    "        j = np.array(group.lonbins_ind)\n",
    "\n",
    "        invar_BINNED[i[0],j[0]] = group.invar\n",
    "\n",
    "        invar_binned_ave[i[0],j[0]] = np.nanmean(group.invar)\n",
    "        \n",
    "    # create pcolormesh lat/lon vals\n",
    "    \n",
    "    # extend longitude by 2\n",
    "    lon_extend = np.zeros(lonbins.size+2)\n",
    "    # fill in internal values\n",
    "    lon_extend[1:-1] = lonbins # fill up with original values\n",
    "    # fill in extra endpoints\n",
    "    lon_extend[0] = lonbins[0]-np.diff(lonbins)[0]\n",
    "    lon_extend[-1] = lonbins[-1]+np.diff(lonbins)[-1]\n",
    "    # calculate the midpoints\n",
    "    lon_pcolormesh_midpoints = lon_extend[:-1]+0.5*(np.diff(lon_extend))\n",
    "\n",
    "    # extend latitude by 2\n",
    "    lat_extend = np.zeros(latbins.size+2)\n",
    "    # fill in internal values\n",
    "    lat_extend[1:-1] = latbins\n",
    "    # fill in extra endpoints\n",
    "    lat_extend[0] = latbins[0]-np.diff(latbins)[0]\n",
    "    lat_extend[-1] = latbins[-1]+np.diff(latbins)[-1]\n",
    "    # calculate the midpoints\n",
    "    lat_pcolormesh_midpoints = lat_extend[:-1]+0.5*(np.diff(lat_extend))\n",
    "    \n",
    "\n",
    "    return(np.array(invar_binned_ave,dtype = float), \n",
    "           lonbins,latbins,lon_pcolormesh_midpoints,lat_pcolormesh_midpoints)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binwidth = 1\n",
    "\n",
    "# TCD/OCD Binned\n",
    "TCD_binned_ave, lonbins, latbins,lonp,latp = latlonbin(ds.TCD,ds.lat,ds.lon,ds.time,binwidth)\n",
    "OCD_binned_ave,_,_,_,_ = latlonbin(ds.OCD,ds.lat,ds.lon,ds.time,binwidth)\n",
    "\n",
    "TCD_sm_10_binned_ave, lonbins, latbins,lonp,latp = latlonbin(ds.TCD_sm_10,ds.lat,ds.lon,ds.time,binwidth)\n",
    "OCD_sm_10_binned_ave,_,_,_,_ = latlonbin(ds.OCD_sm_10,ds.lat,ds.lon,ds.time,binwidth)\n",
    "    \n",
    "# add to dataset\n",
    "ds['TCD_binned_ave'] = xr.DataArray(TCD_binned_ave,\n",
    "                                   dims = ['latbins','lonbins'],coords =[latbins,lonbins])\n",
    "\n",
    "ds['OCD_binned_ave'] = xr.DataArray(OCD_binned_ave,\n",
    "                                   dims = ['latbins','lonbins'],coords =[latbins,lonbins])\n",
    "\n",
    "# add to dataset\n",
    "ds['TCD_sm_10_binned_ave'] = xr.DataArray(TCD_sm_10_binned_ave,\n",
    "                                   dims = ['latbins','lonbins'],coords =[latbins,lonbins])\n",
    "\n",
    "ds['OCD_sm_10_binned_ave'] = xr.DataArray(OCD_sm_10_binned_ave,\n",
    "                                   dims = ['latbins','lonbins'],coords =[latbins,lonbins])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plots of Binned and Vertically Smoothed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting\n",
    "def add_land(ax,bounds):\n",
    "    from cartopy.mpl.gridliner import LONGITUDE_FORMATTER, LATITUDE_FORMATTER\n",
    "    ax.add_feature(cfeature.LAND,color='gray',zorder = 2)\n",
    "    ax.background_patch.set_facecolor('k')\n",
    "    ax.coastlines(resolution='110m',zorder = 2)\n",
    "    g = ax.gridlines(draw_labels=True,alpha=0)\n",
    "    g.xlabels_top = False\n",
    "    g.ylabels_right = False\n",
    "    g.xlabel_style = {'size': 15}\n",
    "    g.ylabel_style = {'size': 15}\n",
    "    g.xformatter = LONGITUDE_FORMATTER\n",
    "    g.yformatter = LATITUDE_FORMATTER\n",
    "    ax.axes.axis('tight')\n",
    "    ax.set_extent(bounds, crs=ccrs.PlateCarree())\n",
    "\n",
    "# limits\n",
    "cmin = 10\n",
    "cmax =160\n",
    "bounds = [35,120,-20,30]\n",
    "cmap = plt.cm.Spectral # plt.cm.PuOr\n",
    "\n",
    "fig, axes = plt.subplots(nrows = 2, ncols = 2,figsize=(16,10),subplot_kw={'projection': ccrs.PlateCarree()})\n",
    "\n",
    "p = axes[0,0].pcolor(lonp,latp,ds.TCD_binned_ave,cmap=cmap,vmin=cmin,vmax=cmax,\n",
    "                       transform=ccrs.PlateCarree())\n",
    "add_land(axes[0,0],bounds)\n",
    "axes[0,0].set_extent(bounds, crs=ccrs.PlateCarree())\n",
    "axes[0,0].set_title('TCD Raw')\n",
    "axes[0,0].set_xlabel('Longitude')\n",
    "axes[0,0].set_ylabel('Latitude')\n",
    "\n",
    "p2 = axes[0,1].pcolormesh(lonp,latp,ds.TCD_sm_10_binned_ave,cmap=cmap, vmin=cmin,vmax=cmax,\n",
    "                       transform=ccrs.PlateCarree())\n",
    "add_land(axes[0,1],bounds)\n",
    "axes[0,1].set_title('TCD Vertically Smoothed')\n",
    "axes[0,1].set_xlabel('Longitude')\n",
    "\n",
    "p4 = axes[1,0].pcolormesh(lonp,latp,ds.OCD_binned_ave,cmap=cmap,vmin=cmin,vmax=cmax)\n",
    "add_land(axes[1,0],bounds)\n",
    "axes[1,0].set_extent(bounds, crs=ccrs.PlateCarree())\n",
    "axes[1,0].set_title('OCD Raw')\n",
    "axes[1,0].set_xlabel('Longitude')\n",
    "axes[1,0].set_ylabel('Latitude')\n",
    "\n",
    "p5 = axes[1,1].pcolormesh(lonp,latp,ds.OCD_sm_10_binned_ave,cmap=cmap, vmin=cmin,vmax=cmax,\n",
    "                       transform=ccrs.PlateCarree())\n",
    "add_land(axes[1,1],bounds)\n",
    "axes[1,1].set_title('OCD Vertically Smoothed')\n",
    "axes[1,1].set_xlabel('Longitude')\n",
    "\n",
    "\n",
    "cbar_ax = fig.add_axes([0.925, 0.125, 0.02, 0.75])\n",
    "cbar = fig.colorbar(p,cax=cbar_ax, pad=0.04)\n",
    "cbar.set_label('Pressure ($dbar$)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussian Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaus_filter_nan(img,sigma):\n",
    "    from astropy.convolution import convolve\n",
    "    from astropy.convolution import Gaussian2DKernel\n",
    "    \n",
    "    kernel = Gaussian2DKernel(x_stddev=1)\n",
    "    img_conv = convolve(img, kernel)\n",
    "\n",
    "    # set original nan points back to nans\n",
    "    img_conv[np.isnan(img)] = np.nan\n",
    "\n",
    "    return img_conv\n",
    "\n",
    "# add to dataset\n",
    "ds['TCD_sm_10_binned_ave_filt'] = xr.DataArray(gaus_filter_nan(ds.TCD_sm_10_binned_ave,1),\n",
    "                                   dims = ['latbins','lonbins'],coords =[latbins,lonbins])\n",
    "\n",
    "ds['OCD_sm_10_binned_ave_filt'] = xr.DataArray(gaus_filter_nan(ds.OCD_sm_10_binned_ave,1),\n",
    "                                   dims = ['latbins','lonbins'],coords =[latbins,lonbins])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plots of Raw, Smoothed, and Gaussian Filtered and Smoothed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting\n",
    "def add_land(ax,bounds):\n",
    "    from cartopy.mpl.gridliner import LONGITUDE_FORMATTER, LATITUDE_FORMATTER\n",
    "    ax.add_feature(cfeature.LAND,color='gray',zorder = 2)\n",
    "    ax.background_patch.set_facecolor('k')\n",
    "    ax.coastlines(resolution='110m',zorder = 2)\n",
    "    g = ax.gridlines(draw_labels=True,alpha=0)\n",
    "    g.xlabels_top = False\n",
    "    g.ylabels_right = False\n",
    "    g.xlabel_style = {'size': 15}\n",
    "    g.ylabel_style = {'size': 15}\n",
    "    g.xformatter = LONGITUDE_FORMATTER\n",
    "    g.yformatter = LATITUDE_FORMATTER\n",
    "    ax.axes.axis('tight')\n",
    "    ax.set_extent(bounds, crs=ccrs.PlateCarree())\n",
    "\n",
    "# limits\n",
    "cmin = 20\n",
    "cmax = 160\n",
    "bounds = [35,120,-20,30]\n",
    "cmap = plt.cm.Spectral # plt.cm.PuOr\n",
    "\n",
    "fig, axes = plt.subplots(nrows = 2, ncols = 2,figsize=(16,10),subplot_kw={'projection': ccrs.PlateCarree()})\n",
    "\n",
    "p = axes[0,0].pcolor(lonp,latp,ds.TCD_binned_ave,cmap=cmap,vmin=cmin,vmax=cmax,\n",
    "                       transform=ccrs.PlateCarree())\n",
    "add_land(axes[0,0],bounds)\n",
    "axes[0,0].set_extent(bounds, crs=ccrs.PlateCarree())\n",
    "axes[0,0].set_title('TCD Raw')\n",
    "axes[0,0].set_xlabel('Longitude')\n",
    "axes[0,0].set_ylabel('Latitude')\n",
    "\n",
    "p2 = axes[0,1].pcolormesh(lonp,latp,ds.TCD_sm_10_binned_ave_filt,cmap=cmap, vmin=cmin,vmax=cmax,\n",
    "                       transform=ccrs.PlateCarree())\n",
    "add_land(axes[0,1],bounds)\n",
    "axes[0,1].set_title('TCD Smoothed and Filtered')\n",
    "axes[0,1].set_xlabel('Longitude')\n",
    "\n",
    "p4 = axes[1,0].pcolormesh(lonp,latp,ds.OCD_binned_ave,cmap=cmap,vmin=cmin,vmax=cmax)\n",
    "add_land(axes[1,0],bounds)\n",
    "axes[1,0].set_extent(bounds, crs=ccrs.PlateCarree())\n",
    "axes[1,0].set_title('OCD Raw')\n",
    "axes[1,0].set_xlabel('Longitude')\n",
    "axes[1,0].set_ylabel('Latitude')\n",
    "\n",
    "p5 = axes[1,1].pcolormesh(lonp,latp,ds.OCD_sm_10_binned_ave_filt,cmap=cmap, vmin=cmin,vmax=cmax,\n",
    "                       transform=ccrs.PlateCarree())\n",
    "add_land(axes[1,1],bounds)\n",
    "axes[1,1].set_title('OCD Smoothed and Filtered')\n",
    "axes[1,1].set_xlabel('Longitude')\n",
    "\n",
    "\n",
    "cbar_ax = fig.add_axes([0.925, 0.125, 0.02, 0.75])\n",
    "cbar = fig.colorbar(p,cax=cbar_ax, pad=0.04)\n",
    "cbar.set_label('Pressure ($dbar$)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Months of lowest TCD and OCD with O and T vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def latlonbin(TCD,OCD,lat,lon,date,binwidth):\n",
    "    import numpy as np\n",
    "    # find TCD anomaly and do correlatinos there.\n",
    "    # create a pandas dataframe\n",
    "    df = pd.DataFrame(dict(\n",
    "            TCD=np.array(TCD),\n",
    "            OCD=np.array(OCD),\n",
    "            TCD_masked=np.array(TCD),\n",
    "            OCD_masked=np.array(OCD),\n",
    "            lat=np.array(lat),\n",
    "            lon=np.array(lon),\n",
    "            date = ds.time,\n",
    "            prof = np.array(ds.prof)\n",
    "        ))\n",
    "\n",
    "    # add in a column for the month\n",
    "    df['month'] = pd.DatetimeIndex(df['date']).month\n",
    "\n",
    "    # set to nans all the values where there isn't a tcd and ocd value\n",
    "\n",
    "    ind = (df['TCD'].isnull()) | (df['OCD'].isnull()) \n",
    "    df.loc[(ind),'TCD_masked']=np.nan\n",
    "    df.loc[(ind),'OCD_masked']=np.nan\n",
    "\n",
    "    # create 1 degree bins\n",
    "    binwidth = 1\n",
    "    # latedges = np.arange(ds.lat.min()-(binwidth/2),ds.lat.max()+(binwidth/2),binwidth)\n",
    "    latedges = np.arange(ds.lat.min(),ds.lat.max(),binwidth)\n",
    "    lat_inds = list(range(len(latedges)-1))\n",
    "\n",
    "    # lonedges = np.arange(ds.lon.min()-(binwidth/2),ds.lon.max()+(binwidth/2),binwidth)\n",
    "    lonedges = np.arange(ds.lon.min(),ds.lon.max(),binwidth)\n",
    "    lon_inds = list(range(len(lonedges)-1))\n",
    "\n",
    "    latbins = latedges[1:]-(binwidth/2)\n",
    "    lonbins = lonedges[1:]-(binwidth/2)\n",
    "\n",
    "    df['latedges'] = pd.cut(ds.lat, latedges)\n",
    "    df['lonedges'] = pd.cut(ds.lon, lonedges)\n",
    "    df['latbins_ind'] = pd.cut(ds.lat, latedges,labels = lat_inds)\n",
    "    df['lonbins_ind'] = pd.cut(ds.lon, lonedges,labels = lon_inds)\n",
    "    df['lat_lon_indx']=df.groupby(['latbins_ind', 'lonbins_ind']).ngroup()\n",
    "    grouped = df.groupby(['latbins_ind', 'lonbins_ind'])\n",
    "\n",
    "\n",
    "    min_OCD = np.zeros((len(latbins),len(lonbins)), dtype=np.ndarray)\n",
    "    min_OCD[:] = np.nan\n",
    "\n",
    "    min_OCD_month = np.zeros((len(latbins),len(lonbins)), dtype=np.ndarray)\n",
    "    min_OCD_month[:] = np.nan\n",
    "\n",
    "    min_TCD = np.zeros((len(latbins),len(lonbins)), dtype=np.ndarray)\n",
    "    min_TCD[:] = np.nan\n",
    "\n",
    "    min_TCD_month = np.zeros((len(latbins),len(lonbins)), dtype=np.ndarray)\n",
    "    min_TCD_month[:] = np.nan\n",
    "\n",
    "    #extract the data for each group\n",
    "    for name, group in grouped:\n",
    "        i = np.array(group.latbins_ind)\n",
    "        j = np.array(group.lonbins_ind)\n",
    "        month = np.array(group.month)\n",
    "\n",
    "\n",
    "        # find month of minimum OCD\n",
    "        if ~np.isnan(np.nanmin(group.OCD_masked)):\n",
    "            min_OCD[i[0],j[0]] = np.nanmin(group.OCD_masked)\n",
    "            ind = np.nanargmin(group.OCD_masked)\n",
    "            min_OCD_month[i[0],j[0]] = month[ind]\n",
    "        if ~np.isnan(np.nanmin(group.TCD_masked)): \n",
    "            min_TCD[i[0],j[0]] = np.nanmin(group.TCD_masked)\n",
    "            ind = np.nanargmin(group.TCD_masked)\n",
    "            min_TCD_month[i[0],j[0]] = month[ind]\n",
    "            \n",
    "    # create pcolormesh lat/lon vals\n",
    "    \n",
    "    # extend longitude by 2\n",
    "    lon_extend = np.zeros(lonbins.size+2)\n",
    "    # fill in internal values\n",
    "    lon_extend[1:-1] = lonbins # fill up with original values\n",
    "    # fill in extra endpoints\n",
    "    lon_extend[0] = lonbins[0]-np.diff(lonbins)[0]\n",
    "    lon_extend[-1] = lonbins[-1]+np.diff(lonbins)[-1]\n",
    "    # calculate the midpoints\n",
    "    lon_pcolormesh_midpoints = lon_extend[:-1]+0.5*(np.diff(lon_extend))\n",
    "\n",
    "    # extend latitude by 2\n",
    "    lat_extend = np.zeros(latbins.size+2)\n",
    "    # fill in internal values\n",
    "    lat_extend[1:-1] = latbins\n",
    "    # fill in extra endpoints\n",
    "    lat_extend[0] = latbins[0]-np.diff(latbins)[0]\n",
    "    lat_extend[-1] = latbins[-1]+np.diff(latbins)[-1]\n",
    "    # calculate the midpoints\n",
    "    lat_pcolormesh_midpoints = lat_extend[:-1]+0.5*(np.diff(lat_extend))\n",
    "\n",
    "    return(np.array(min_TCD_month,dtype = float), np.array(min_OCD_month,dtype = float),\n",
    "           lonbins,latbins,lon_pcolormesh_midpoints,lat_pcolormesh_midpoints)\n",
    "\n",
    "# TCD/OCD Binned\n",
    "min_TCD_month, min_OCD_month, lonbins, latbins,lonp,latp = latlonbin(ds.TCD,ds.OCD,ds.lat,ds.lon,ds.time,binwidth)\n",
    "\n",
    "min_TCD_month_sm_10, min_OCD_month_sm_10, lonbins, latbins,lonp,latp = latlonbin(ds.TCD_sm_10,ds.OCD_sm_10,ds.lat,ds.lon,ds.time,binwidth)\n",
    "   \n",
    "min_TCD_month_sm_10_filt = gaus_filter_nan(min_TCD_month_sm_10,1)\n",
    "min_OCD_month_sm_10_filt = gaus_filter_nan(min_OCD_month_sm_10,1)\n",
    "    \n",
    "# figure out why it isn't saving correctly to the ds!\n",
    "    \n",
    "# ds['min_OCD'] = xr.DataArray(np.array(min_OCD,dtype = float),\n",
    "#                                    dims = ['latbins','lonbins'],coords =[latbins,lonbins])\n",
    "\n",
    "# ds['min_OCD_month'] = xr.DataArray(min_OCD_month,\n",
    "#                                    dims = ['latbins','lonbins'],coords =[latbins,lonbins])\n",
    "\n",
    "\n",
    "# ds['min_TCD'] = xr.DataArray(np.array(min_TCD,dtype = float),\n",
    "#                                    dims = ['latbins','lonbins'],coords =[latbins,lonbins])\n",
    "\n",
    "# ds['min_TCD_month'] = xr.DataArray(np.array(min_TCD_month,dtype = float),\n",
    "#                                    dims = ['latbins','lonbins'],coords =[latbins,lonbins])\n",
    "\n",
    "# # add to dataset\n",
    "# ds['min_TCD_month_sm_10_filt'] = xr.DataArray(gaus_filter_nan(min_TCD_month_sm_10,1),\n",
    "#                                    dims = ['latbins','lonbins'],coords =[latbins,lonbins])\n",
    "\n",
    "# ds['min_OCD_month_sm_10_filt'] = xr.DataArray(gaus_filter_nan(min_OCD_month_sm_10,1),\n",
    "#                                    dims = ['latbins','lonbins'],coords =[latbins,lonbins])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting\n",
    "import cmocean\n",
    "\n",
    "def add_land(ax,bounds):\n",
    "    from cartopy.mpl.gridliner import LONGITUDE_FORMATTER, LATITUDE_FORMATTER\n",
    "    ax.add_feature(cfeature.LAND,color='gray',zorder = 2)\n",
    "    ax.background_patch.set_facecolor('k')\n",
    "    ax.coastlines(resolution='110m',zorder = 2)\n",
    "    g = ax.gridlines(draw_labels=True,alpha=0)\n",
    "    g.xlabels_top = False\n",
    "    g.ylabels_right = False\n",
    "    g.xlabel_style = {'size': 15}\n",
    "    g.ylabel_style = {'size': 15}\n",
    "    g.xformatter = LONGITUDE_FORMATTER\n",
    "    g.yformatter = LATITUDE_FORMATTER\n",
    "    ax.axes.axis('tight')\n",
    "    ax.set_extent(bounds, crs=ccrs.PlateCarree())\n",
    "\n",
    "# limits\n",
    "cmin = 20\n",
    "cmax = 160\n",
    "bounds = [35,100,0,30]\n",
    "cmap = plt.cm.RdBu_r #cmocean.cm.phase\n",
    "\n",
    "fig, axes = plt.subplots(nrows = 2, ncols = 2,figsize=(16,8),subplot_kw={'projection': ccrs.PlateCarree()})\n",
    "\n",
    "p = axes[0,0].pcolor(lonp,latp,min_TCD_month_sm_10,cmap=cmap,\n",
    "                       transform=ccrs.PlateCarree())\n",
    "add_land(axes[0,0],bounds)\n",
    "axes[0,0].set_extent(bounds, crs=ccrs.PlateCarree())\n",
    "axes[0,0].set_title('Month of Minimum TCD')\n",
    "axes[0,0].set_xlabel('Longitude')\n",
    "axes[0,0].set_ylabel('Latitude')\n",
    "\n",
    "p2 = axes[0,1].pcolormesh(lonp,latp,min_TCD_month_sm_10_filt,cmap=cmap,\n",
    "                       transform=ccrs.PlateCarree())\n",
    "add_land(axes[0,1],bounds)\n",
    "axes[0,1].set_title('Month of Minimum TCD Smoothed and Filtered')\n",
    "axes[0,1].set_xlabel('Longitude')\n",
    "\n",
    "p4 = axes[1,0].pcolormesh(lonp,latp,min_OCD_month_sm_10,cmap=cmap,\n",
    "                       transform=ccrs.PlateCarree())\n",
    "add_land(axes[1,0],bounds)\n",
    "axes[1,0].set_title('Month of Minimum OCD')\n",
    "axes[1,0].set_xlabel('Longitude')\n",
    "axes[1,0].set_ylabel('Latitude')\n",
    "\n",
    "p5 = axes[1,1].pcolormesh(lonp,latp,min_OCD_month_sm_10_filt,cmap=cmap,\n",
    "                       transform=ccrs.PlateCarree())\n",
    "add_land(axes[1,1],bounds)\n",
    "axes[1,1].set_title('Month of Minimum OCD Smoothed and Filtered')\n",
    "axes[1,1].set_xlabel('Longitude')\n",
    "\n",
    "\n",
    "cbar_ax = fig.add_axes([0.925, 0.125, 0.02, 0.75])\n",
    "cbar = fig.colorbar(p,cax=cbar_ax, pad=0.04,\n",
    "                    ticks = np.arange(1,13))\n",
    "cbar.set_ticklabels(['Jan','Feb','Mar','Apr','May','Jun','Jul','Aug','Sep','Oct','Nov','Dec'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find Correlations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # my attempt without pandas\n",
    "# import itertools\n",
    "\n",
    "# binwidth = 1\n",
    "# latedges =  list(np.arange(ds.lat.min()-(binwidth/2),ds.lat.max()+(binwidth/2),binwidth))\n",
    "# lonedges =  list(np.arange(ds.lon.min()-(binwidth/2),ds.lon.max()+(binwidth/2),binwidth))\n",
    "\n",
    "# TCD_BINNED = np.zeros((len(latedges),len(lonedges)), dtype=np.ndarray)\n",
    "\n",
    "# for i in range(len(latedges)-1):\n",
    "#     for j in range(len(lonedges)-1):\n",
    "# #         print(i,j)\n",
    "    \n",
    "#         ind = (ds.lat>= latedges[i]) & (ds.lat<=latedges[i+1]) & (ds.lon>= lonedges[j]) & (ds.lon<=lonedges[j+1])\n",
    "        \n",
    "#         TCD_BINNED[i,j] = np.array(ds.TCD[ind])\n",
    "#         TCD_binned_ave = np.nanmean(ds.TCD[ind])\n",
    "\n",
    "# set values to nans for the correlations\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # convert to np array to work with the stats.binned stuff.\n",
    "# lon = np.array(ds.lon)\n",
    "# lat = np.array(ds.lat)\n",
    "\n",
    "# # create 1 degree bins\n",
    "# latedges = np.r_[ds.lat.min():ds.lat.max():1]\n",
    "# lonedges = np.r_[ds.lon.min():ds.lon.max():1]\n",
    "\n",
    "# TCD_binned, yedges, xedges, binnumber = stats.binned_statistic_2d(lat[~np.isnan(TCD)], \n",
    "#                                                                  lon[~np.isnan(TCD)], TCD[~np.isnan(TCD)], \n",
    "#                                                                  'mean', bins=[latedges, lonedges])\n",
    "# OCD_binned, yedges, xedges, binnumber = stats.binned_statistic_2d(lat[~np.isnan(OCD)], \n",
    "#                                                                  lon[~np.isnan(OCD)], OCD[~np.isnan(OCD)], \n",
    "#                                                                  'mean', bins=[latedges, lonedges])\n",
    "\n",
    "# TCD_sm_10_binned, yedges, xedges, binnumber = stats.binned_statistic_2d(lat[~np.isnan(TCD_sm_10)], \n",
    "#                                                                  lon[~np.isnan(TCD_sm_10)], \n",
    "#                                                                  TCD_sm_10[~np.isnan(TCD_sm_10)], \n",
    "#                                                                  'mean', bins=[latedges, lonedges])\n",
    "\n",
    "# OCD_sm_10_binned, yedges, xedges, binnumber = stats.binned_statistic_2d(lat[~np.isnan(OCD_sm_10)], \n",
    "#                                                                  lon[~np.isnan(OCD_sm_10)], \n",
    "#                                                                  OCD_sm_10[~np.isnan(OCD_sm_10)], \n",
    "#                                                                  'mean', bins=[latedges, lonedges])\n",
    "\n",
    "# lonbins = xedges[1:] - 1/2\n",
    "# latbins = yedges[1:] - 1/2\n",
    "\n",
    "# # add to dataset\n",
    "# ds['lonbins'] = xr.DataArray(lonbins,dims = ['lonbins'],coords =[lonbins])\n",
    "# ds['latbins'] = xr.DataArray(latbins,dims = ['latbins'],coords =[latbins])\n",
    "\n",
    "# ds['TCD_binned'] = xr.DataArray(TCD_binned,dims = ['latbins','lonbins'],coords =[latbins,lonbins])\n",
    "# ds['OCD_binned'] = xr.DataArray(OCD_binned,dims = ['latbins','lonbins'],coords =[latbins,lonbins])\n",
    "\n",
    "# ds['TCD_sm_10_binned'] = xr.DataArray(TCD_sm_10_binned,dims = ['latbins','lonbins'],coords =[latbins,lonbins])\n",
    "# ds['OCD_sm_10_binned'] = xr.DataArray(OCD_sm_10_binned,dims = ['latbins','lonbins'],coords =[latbins,lonbins])\n",
    "\n",
    "# # apply a Guassian filter with st = 1 --- figure out how to deal with the coastlines later\n",
    "# TCD_sm_10_binned_filtered = xr.DataArray(gaussian_filter(ds.TCD_sm_10_binned,\n",
    "#                                                          sigma=1),coords = [ds.latbins,ds.lonbins])\n",
    "\n",
    "# OCD_sm_10_binned_filtered = xr.DataArray(gaussian_filter(ds.OCD_sm_10_binned,\n",
    "#                                                        sigma=1),coords = [ds.latbins,ds.lonbins])\n",
    "# # add to dataset\n",
    "# ds['TCD_sm_10_binned_filtered'] = xr.DataArray(TCD_sm_10_binned_filtered,dims = ['latbins','lonbins'],coords =[latbins,lonbins])\n",
    "# ds['OCD_sm_10_binned_filtered'] = xr.DataArray(OCD_sm_10_binned_filtered,dims = ['latbins','lonbins'],coords =[latbins,lonbins])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # find TCD anomaly and do correlatinos there.\n",
    "# # create a pandas dataframe\n",
    "# df = pd.DataFrame(dict(\n",
    "#         TCD=np.array(ds.TCD),\n",
    "#         OCD=np.array(ds.OCD),\n",
    "#         TCD_masked=np.array(ds.TCD),\n",
    "#         OCD_masked=np.array(ds.OCD),\n",
    "#         lat=np.array(ds.lat),\n",
    "#         lon=np.array(ds.lon),\n",
    "#         date = ds.time,\n",
    "#         prof = np.array(ds.prof)\n",
    "#     ))\n",
    "\n",
    "# # add in a column for the month\n",
    "# df['month'] = pd.DatetimeIndex(df['date']).month\n",
    "\n",
    "# # set to nans all the values where there isn't a tcd and ocd value\n",
    "\n",
    "# ind = (df['TCD'].isnull()) | (df['OCD'].isnull()) \n",
    "# df.loc[(ind),'TCD_masked']=np.nan\n",
    "# df.loc[(ind),'OCD_masked']=np.nan\n",
    "\n",
    "# # create 1 degree bins\n",
    "# binwidth = 1\n",
    "# # latedges = np.arange(ds.lat.min()-(binwidth/2),ds.lat.max()+(binwidth/2),binwidth)\n",
    "# latedges = np.arange(ds.lat.min(),ds.lat.max(),binwidth)\n",
    "# lat_inds = list(range(len(latedges)-1))\n",
    "\n",
    "# # lonedges = np.arange(ds.lon.min()-(binwidth/2),ds.lon.max()+(binwidth/2),binwidth)\n",
    "# lonedges = np.arange(ds.lon.min(),ds.lon.max(),binwidth)\n",
    "# lon_inds = list(range(len(lonedges)-1))\n",
    "\n",
    "# latbins = latedges[1:]-(binwidth/2)\n",
    "# lonbins = lonedges[1:]-(binwidth/2)\n",
    "\n",
    "# df['latedges'] = pd.cut(ds.lat, latedges)\n",
    "# df['lonedges'] = pd.cut(ds.lon, lonedges)\n",
    "# df['latbins_ind'] = pd.cut(ds.lat, latedges,labels = lat_inds)\n",
    "# df['lonbins_ind'] = pd.cut(ds.lon, lonedges,labels = lon_inds)\n",
    "# df['lat_lon_indx']=df.groupby(['latbins_ind', 'lonbins_ind']).ngroup()\n",
    "# grouped = df.groupby(['latbins_ind', 'lonbins_ind'])\n",
    "\n",
    "# TCD_BINNED = np.zeros((len(latbins),len(lonbins)), dtype=np.ndarray)\n",
    "# TCD_BINNED[:] = np.nan\n",
    "# OCD_BINNED = np.zeros((len(latbins),len(lonbins)), dtype=np.ndarray)\n",
    "# OCD_BINNED[:] = np.nan\n",
    "\n",
    "# TCD_binned_ave = np.zeros((len(latbins),len(lonbins)), dtype=np.ndarray)\n",
    "# TCD_binned_ave[:] = np.nan\n",
    "\n",
    "# OCD_binned_ave = np.zeros((len(latbins),len(lonbins)), dtype=np.ndarray)\n",
    "# OCD_binned_ave[:] = np.nan\n",
    "\n",
    "# min_OCD = np.zeros((len(latbins),len(lonbins)), dtype=np.ndarray)\n",
    "# min_OCD[:] = np.nan\n",
    "\n",
    "# min_OCD_month = np.zeros((len(latbins),len(lonbins)), dtype=np.ndarray)\n",
    "# min_OCD_month[:] = np.nan\n",
    "\n",
    "# min_TCD = np.zeros((len(latbins),len(lonbins)), dtype=np.ndarray)\n",
    "# min_TCD[:] = np.nan\n",
    "\n",
    "# min_TCD_month = np.zeros((len(latbins),len(lonbins)), dtype=np.ndarray)\n",
    "# min_TCD_month[:] = np.nan\n",
    "\n",
    "# #extract the data for each group\n",
    "# for name, group in grouped:\n",
    "#     i = np.array(group.latbins_ind)\n",
    "#     j = np.array(group.lonbins_ind)\n",
    "#     month = np.array(group.month)\n",
    "    \n",
    "#     TCD_BINNED[i[0],j[0]] = group.TCD\n",
    "#     OCD_BINNED[i[0],j[0]] = group.OCD\n",
    "    \n",
    "#     TCD_binned_ave[i[0],j[0]] = np.nanmean(group.TCD)\n",
    "#     OCD_binned_ave[i[0],j[0]] = np.nanmean(group.OCD)\n",
    "    \n",
    "#     # find month of minimum OCD\n",
    "#     if ~np.isnan(np.nanmin(group.OCD_masked)):\n",
    "#         min_OCD[i[0],j[0]] = np.nanmin(group.OCD_masked)\n",
    "#         ind = np.nanargmin(group.OCD_masked)\n",
    "#         min_OCD_month[i[0],j[0]] = month[ind]\n",
    "#     if ~np.isnan(np.nanmin(group.TCD_masked)): \n",
    "#         min_TCD[i[0],j[0]] = np.nanmin(group.TCD_masked)\n",
    "#         ind = np.nanargmin(group.TCD_masked)\n",
    "#         min_TCD_month[i[0],j[0]] = month[ind]\n",
    "    \n",
    "#     # find average doxy during month of minmum OCD\n",
    "    \n",
    "#     # seasonal correlations\n",
    "#     # used masked variables\n",
    "    \n",
    "# #     scipy.stats.pearsonr(x, y)[source]Â¶\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
