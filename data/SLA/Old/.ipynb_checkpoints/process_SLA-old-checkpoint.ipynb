{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Packages -----------------------------------------------#\n",
    "\n",
    "import os\n",
    "\n",
    "# Data Analysis\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import metpy.calc as mpcalc\n",
    "import matplotlib.dates as dates\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.interpolate import griddata\n",
    "\n",
    "# Timing Processes and Progress\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "# make sure the figures plot inline rather than at the end\n",
    "%matplotlib inline\n",
    "\n",
    "# get data from tigress\n",
    "path = '/home/jennap/projects/LRGROUP/shared_data/ssh_AVISO/'\n",
    "# slainfn = 'all_adt_sla_global_twosat_phy_l4_vDT2018_daily_1994_2018.nc'\n",
    "slainfn = 'all_adt_sla_global_twosat_phy_l4_vDT2018_daily_1994_2020_03_01.nc'\n",
    "\n",
    "ds = xr.open_dataset(path + slainfn)\n",
    "ds\n",
    "#print(ds.keys())\n",
    "\n",
    "# Subset ------------------------------------------------#\n",
    "# Create slice variables to subset domain before finding means\n",
    "lat_slice = slice(-20, 30) # bounds inclusive\n",
    "lon_slice = slice(35, 120) # bounds inclusive\n",
    "\n",
    "# Get data, selecting lat/lon slice\n",
    "daily_sla = ds['sla'].sel(latitude=lat_slice,longitude=lon_slice)\n",
    "lat = daily_sla.latitude.values\n",
    "lon = daily_sla.longitude.values\n",
    "\n",
    "del lat_slice, lon_slice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The absolute dynamic topography is the sea surface height above geoid; the adt is obtained as follows: adt=sla+mdt where mdt is the mean dynamic topography; see the product user manual for details'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.adt.comment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detrend SLA\n",
    "\n",
    "Resources: [link](https://ecco-v4-python-tutorial.readthedocs.io/ECCO_v4_Example_calculations_with_scalar_quantities.html), [link](https://groups.google.com/g/xarray/c/fz7HHgpgwk0), [link](https://stackoverflow.com/questions/28647172/numpy-polyfit-doesnt-handle-nan-values), [link](https://stackoverflow.com/questions/28647172/numpy-polyfit-doesnt-handle-nan-values), [link](https://stackoverflow.com/questions/17638137/curve-fitting-to-a-time-series-in-the-format-datetime)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2h 1min 15s, sys: 4min 47s, total: 2h 6min 2s\n",
      "Wall time: 10min 14s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# stack lat and lon into a single dimension called allpoints\n",
    "stacked = daily_sla.stack(allpoints=['latitude','longitude'])\n",
    "\n",
    "# set places where there are nans to zero since polyfit can't deal with them\n",
    "stacked_nonan = stacked.fillna(0)\n",
    "\n",
    "# convert date to a number to polyfit can handle it\n",
    "datenum = dates.date2num(stacked_nonan.time)\n",
    "daily_sla_slope, daily_sla_intercept = np.polyfit(datenum, stacked_nonan, 1)\n",
    "\n",
    "#reshape the data\n",
    "daily_sla_slope = np.reshape(daily_sla_slope, daily_sla.shape[1:3])\n",
    "daily_sla_intercept = np.reshape(daily_sla_intercept, daily_sla.shape[1:3])\n",
    "\n",
    "# define a function to compute a linear trend of a timeseries\n",
    "def linear_detrend(y):\n",
    "    x = dates.date2num(y.time)\n",
    "    m, b = np.polyfit(x, y, 1)\n",
    "    # we need to return a dataarray or else xarray's groupby won't be happy\n",
    "    return xr.DataArray(y - (m*x + b))\n",
    "\n",
    "# apply the function over allpoints to calculate the trend at each point\n",
    "daily_sla_dtrnd = stacked_nonan.groupby('allpoints').apply(linear_detrend)\n",
    "# unstack back to lat lon coordinates\n",
    "daily_sla_dtrnd = daily_sla_dtrnd.unstack('allpoints')\n",
    "\n",
    "# fill all points we set originally to zero back to nan\n",
    "daily_sla_dtrnd = daily_sla_dtrnd.where(~np.isnan(daily_sla))\n",
    "\n",
    "# delete trended data to save on memory\n",
    "del daily_sla,ds, stacked, stacked_nonan\n",
    "\n",
    "# make plot for this to show difference.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Downsample to Monthly and Seasonal Temporal Resolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jennap/anaconda3/lib/python3.7/site-packages/xarray/core/nanops.py:161: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis=axis, dtype=dtype)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5min 45s, sys: 15 s, total: 6min\n",
      "Wall time: 12 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# monthly\n",
    "mon_sla_dtrnd = daily_sla_dtrnd.resample(time='1MS').mean(dim=\"time\")\n",
    "# seasonal\n",
    "seas_sla_dtrnd = daily_sla_dtrnd.resample(time='QS-DEC').mean(dim=\"time\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find Climatologies \n",
    "Resources: [link](http://xarray.pydata.org/en/stable/examples/monthly-means.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jennap/anaconda3/lib/python3.7/site-packages/xarray/core/nanops.py:161: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis=axis, dtype=dtype)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 36s, sys: 6.84 s, total: 1min 43s\n",
      "Wall time: 13.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# -------------------------------------------\n",
    "# weighted seasonal\n",
    "# -------------------------------------------\n",
    "\n",
    "# get months\n",
    "month_length = daily_sla_dtrnd.time.dt.days_in_month\n",
    "\n",
    "# calculate the weights by grouping by 'time.season'.\n",
    "weights = month_length.groupby('time.season') / month_length.groupby('time.season').sum()\n",
    "\n",
    "# calculate the weighted average\n",
    "sla_seas_clim_dtrnd = (daily_sla_dtrnd * weights).groupby('time.season').sum(dim='time')   \n",
    "\n",
    "# set the places that are now zero from the weights to nans\n",
    "sla_seas_clim_dtrnd = sla_seas_clim_dtrnd.where(sla_seas_clim_dtrnd != 0,np.nan) # for some reason .where sets the locations not in the condition to nan by default\n",
    "\n",
    "# -------------------------------------------\n",
    "# monthly\n",
    "# -------------------------------------------\n",
    "\n",
    "sla_mon_clim_dtrnd = daily_sla_dtrnd.groupby('time.month').mean('time') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find Anomalies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8.84 s, sys: 725 ms, total: 9.57 s\n",
      "Wall time: 510 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# # daily data - monthly climatology\n",
    "# daily_sla_mon_anom_dtrnd = daily_sla_dtrnd.groupby('time.month') - sla_mon_clim_dtrnd\n",
    "\n",
    "# monthly avg data - monthly climatology\n",
    "mon_sla_mon_anom_dtrnd = mon_sla_dtrnd.groupby('time.month') - sla_mon_clim_dtrnd\n",
    "\n",
    "# # monthly avg data - seasonal climatology\n",
    "# seas_sla_mon_anom_dtrnd = mon_sla_dtrnd.groupby('time.season') - sla_seas_clim_dtrnd\n",
    "\n",
    "# seasonal avg data - seasonal climatology\n",
    "seas_sla_seas_anom_dtrnd = mon_sla_dtrnd.groupby('time.season') - sla_seas_clim_dtrnd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'os' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-a762c5a1b006>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;31m# delete if already present\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m     \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'os' is not defined"
     ]
    }
   ],
   "source": [
    "# convert to xarray dataset\n",
    "ds=xr.Dataset(coords={'longitude': daily_sla_dtrnd.longitude,\n",
    "                    'latitude': daily_sla_dtrnd.latitude,\n",
    "                    'time': daily_sla_dtrnd.time})\n",
    "\n",
    "# add variables to dataset\n",
    "\n",
    "ds[\"daily_sla_dtrnd\"]=(['time','latitude', 'longitude'],  daily_sla_dtrnd)\n",
    "ds[\"mon_sla_dtrnd\"]=xr.DataArray(mon_sla_dtrnd,dims = ['month_time','latitude', 'longitude'],\n",
    "                     coords =[mon_sla_dtrnd.time,daily_sla_dtrnd.latitude,daily_sla_dtrnd.longitude])\n",
    "ds[\"seas_sla_dtrnd\"]=xr.DataArray(seas_sla_dtrnd,dims = ['season_time','latitude', 'longitude'],\n",
    "                     coords =[seas_sla_dtrnd.time,daily_sla_dtrnd.latitude,daily_sla_dtrnd.longitude])\n",
    "\n",
    "# clim\n",
    "ds[\"sla_mon_clim_dtrnd\"]=xr.DataArray(sla_mon_clim_dtrnd,dims = ['month','latitude', 'longitude'],\n",
    "                     coords =[sla_mon_clim_dtrnd.month,daily_sla_dtrnd.latitude,daily_sla_dtrnd.longitude])\n",
    "ds[\"sla_seas_clim_dtrnd\"]=xr.DataArray(sla_seas_clim_dtrnd,dims = ['season','latitude', 'longitude'],\n",
    "                     coords =[sla_seas_clim_dtrnd.season,daily_sla_dtrnd.latitude,daily_sla_dtrnd.longitude])\n",
    "\n",
    "# anom\n",
    "ds[\"mon_sla_mon_anom_dtrnd\"]=xr.DataArray(mon_sla_mon_anom_dtrnd,dims = ['month_time','latitude', 'longitude'],\n",
    "                     coords =[mon_sla_mon_anom_dtrnd.time,daily_sla_dtrnd.latitude,daily_sla_dtrnd.longitude])\n",
    "ds[\"seas_sla_seas_anom_dtrnd\"]=xr.DataArray(seas_sla_seas_anom_dtrnd,dims = ['season_time','latitude', 'longitude'],\n",
    "                     coords =[seas_sla_seas_anom_dtrnd.time,daily_sla_dtrnd.latitude,daily_sla_dtrnd.longitude])\n",
    "\n",
    "# save_path = '/projects/GEOCLIM/LRGROUP/jennap/Modulation_of_Coastal_Hypoxia_by_the_IOD/data/'\n",
    "outfn = slainfn[:-3] + '_dtrnd.nc'\n",
    "\n",
    "# delete if already present\n",
    "if os.path.isfile(outfn):\n",
    "    os.remove(outfn)\n",
    "\n",
    "ds.to_netcdf(outfn,mode='w',format = \"NETCDF4\")\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
